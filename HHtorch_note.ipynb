{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a08a6ac",
   "metadata": {},
   "source": [
    "## LESSON——3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "f7760ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from functools import reduce\n",
    "def topologic(graph):\n",
    "\n",
    "    sorted_node = []\n",
    "    \n",
    "    while graph:\n",
    "        all_nodes_have_inputs = reduce(lambda a, b: a + b,list(graph.values())) #所有有输入的节点\n",
    "        all_node_have_outputs = list(graph.keys()) #所有有输出的节点\n",
    "        all_nodes_only_have_outputs_no_inputs = set(all_node_have_outputs) - set(all_nodes_have_inputs)\n",
    "    \n",
    "        if all_nodes_only_have_outputs_no_inputs:\n",
    "            node = random.choice(list(all_nodes_only_have_outputs_no_inputs))\n",
    "            \n",
    "            sorted_node.append(node)\n",
    "            \n",
    "            if len(graph) == 1:\n",
    "                sorted_node += graph[node]\n",
    "                \n",
    "            graph.pop(node)\n",
    "            \n",
    "            for _,links in graph.items():\n",
    "                if node in links:links.remove(node)\n",
    "                    \n",
    "        else:\n",
    "            raise TypeError('This graph has circle, which cannot get topological order')\n",
    "    \n",
    "    return sorted_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "d204b528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from functools import reduce\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def topologic(graph):\n",
    "\n",
    "    sorted_node = []\n",
    "    \n",
    "    while graph:\n",
    "        all_nodes_have_inputs = reduce(lambda a, b: a + b,list(graph.values())) #所有有输入的节点\n",
    "        all_node_have_outputs = list(graph.keys()) #所有有输出的节点\n",
    "        all_nodes_only_have_outputs_no_inputs = set(all_node_have_outputs) - set(all_nodes_have_inputs)\n",
    "    \n",
    "        if all_nodes_only_have_outputs_no_inputs:\n",
    "            node = random.choice(list(all_nodes_only_have_outputs_no_inputs))\n",
    "            \n",
    "            sorted_node.append(node)\n",
    "            \n",
    "            if len(graph) == 1:\n",
    "                sorted_node += graph[node]\n",
    "                \n",
    "            graph.pop(node)\n",
    "            \n",
    "            for _,links in graph.items():\n",
    "                if node in links:links.remove(node)\n",
    "                    \n",
    "        else:\n",
    "            raise TypeError('This graph has circle, which cannot get topological order')\n",
    "    \n",
    "    return sorted_node\n",
    "  \n",
    "\n",
    "class Node:\n",
    "    def __init__(self, inputs= [],name = None, is_trainable = False):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "        self.name = name\n",
    "        self.value = None\n",
    "        self.gradients = dict()  #存储loss对某个偏导的值\n",
    "        self.is_trainable = is_trainable\n",
    "        \n",
    "        for node in inputs:\n",
    "            node.outputs.append(self)\n",
    "    def forward(self):\n",
    "#         print(f\"I am {self.name},i calculate myself value by myself\")\n",
    "        pass\n",
    "#     def backward(self):\n",
    "#         for n in self.inputs:\n",
    "#             print('get ∂{}/∂{}'.format(self.name,n.name))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Node:{self.name}'\n",
    "\n",
    "\n",
    "\n",
    "class Placeholder(Node):\n",
    "    def __init__(self,name = None, is_trainable = False):\n",
    "        Node.__init__(self,name = name, is_trainable= is_trainable)\n",
    "\n",
    "    def forward(self):\n",
    "#         print(f\"I am {self.name},my value is {self.value},i calculate myself value, I have been given value\")\n",
    "        pass\n",
    "\n",
    "    def backward(self):\n",
    "        self.gradients[self] = self.outputs[0].gradients[self]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Placeholder:{self.name}'\n",
    "\n",
    "    \n",
    "class Linear(Node):\n",
    "    def __init__(self,x,k,b,name = None):\n",
    "        Node.__init__(self,inputs = [x,k,b],name = name)\n",
    "\n",
    "    def forward(self):\n",
    "#         print(f\"I am {self.name} ,my value is {self.value},i calculate myself value by my self!\")\n",
    "        x, k, b = self.inputs[0], self.inputs[1], self.inputs[2]\n",
    "        self.value = k.value * x.value + b.value\n",
    "    \n",
    "    def backward(self):\n",
    "        x, k, b = self.inputs[0], self.inputs[1], self.inputs[2]\n",
    "        self.gradients[self.inputs[0]] = self.outputs[0].gradients[self] * k.value\n",
    "        self.gradients[self.inputs[1]] = self.outputs[0].gradients[self] * x.value\n",
    "        self.gradients[self.inputs[2]] = self.outputs[0].gradients[self] * 1\n",
    "\n",
    "#         print('self.gradients[self.inputs[0]] {}'.format(self.gradients[self.inputs[0]]))\n",
    "#         print('self.gradients[self.inputs[1]] {}'.format(self.gradients[self.inputs[1]]))\n",
    "#         print('self.gradients[self.inputs[2]] {}'.format(self.gradients[self.inputs[2]]))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Linear:{self.name}'\n",
    "\n",
    "class Sigmoid(Node):\n",
    "    def __init__(self,x,name = None):\n",
    "        Node.__init__(self,inputs = [x],name = name)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def forward(self):\n",
    "#         print(f\"I am {self.name} ,my value is {self.value},i calculate myself value by my self!\")\n",
    "        x = self.inputs[0]\n",
    "        self.value = self._sigmoid(x.value)\n",
    "    \n",
    "    def backward(self):\n",
    "        x = self.inputs[0]\n",
    "        self.gradients[self.inputs[0]] =self.outputs[0].gradients[self] * (self._sigmoid(x.value) * (1 - self._sigmoid(x.value)))\n",
    "#         print('self.gradients[self.inputs[0]] {}'.format(self.gradients[self.inputs[0]]))\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Sigmoid:{self.name}'\n",
    "\n",
    "\n",
    "    \n",
    "class Loss(Node):\n",
    "    \"\"\"MSE\"\"\"\n",
    "    def __init__(self,y,yhat,name = None):\n",
    "        Node.__init__(self,inputs = [y,yhat],name = name)\n",
    "    \n",
    "    def forward(self):\n",
    "#         print(f\"I am {self.name} ,my value is {self.value},i calculate myself value by my self!\")\n",
    "        y,yhat = self.inputs[0], self.inputs[1]\n",
    "        self.value = np.mean((y.value - yhat.value)**2)\n",
    "    \n",
    "    def backward(self):\n",
    "        y,yhat = self.inputs[0], self.inputs[1]\n",
    "        self.gradients[self.inputs[0]] = 2 * np.mean(y.value - yhat.value)\n",
    "        self.gradients[self.inputs[1]] = -2 * np.mean(y.value - yhat.value)\n",
    "\n",
    "#         print('self.gradients[self.inputs[0]] {}'.format(self.gradients[self.inputs[0]]))\n",
    "#         print('self.gradients[self.inputs[1]] {}'.format(self.gradients[self.inputs[1]]))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Sigmoid:{self.name}'\n",
    "    \n",
    "    \n",
    "    \n",
    "def convert_feed_dict_to_graph(feed_dict):\n",
    "    \n",
    "    need_expand = [n for n in feed_dict]\n",
    "    \n",
    "    computing_graph = defaultdict(list)\n",
    "\n",
    "    while need_expand:\n",
    "        n = need_expand.pop(0)\n",
    "\n",
    "        if n in computing_graph:continue\n",
    "        \n",
    "        if isinstance(n,Placeholder): n.value = feed_dict[n]\n",
    "\n",
    "        for m in n.outputs:\n",
    "            computing_graph[n].append(m)\n",
    "            need_expand.append(m)\n",
    "    return computing_graph\n",
    "\n",
    "node_x = Placeholder(name = 'x')\n",
    "node_k = Placeholder(name = 'k',is_trainable = True)\n",
    "node_b = Placeholder(name = 'b',is_trainable = True)\n",
    "node_y = Placeholder(name = 'y')\n",
    "node_linear = Linear(node_x, node_k, node_b,name = 'linear')\n",
    "node_sigmoid = Sigmoid(x = node_linear,name = 'sigmoid')\n",
    "node_loss = Loss(y = node_y, yhat = node_sigmoid,name = 'loss')\n",
    "\n",
    "feed_dict = {\n",
    "    node_x :3,\n",
    "    node_y :random.random(),\n",
    "    node_k :random.random(),\n",
    "    node_b :0.38\n",
    "    }\n",
    "\n",
    "need_feed_value_nodes = [node_x, node_y, node_k, node_b]\n",
    "\n",
    "sorted_node = topologic(convert_feed_dict_to_graph(feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce6d7a8",
   "metadata": {},
   "source": [
    "# 模拟神经网络的计算过程\n",
    "# 就是这个框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "eafde547",
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {\n",
    "    node_x :3,\n",
    "    node_y :random.random(),\n",
    "    node_k :random.random(),\n",
    "    node_b :0.38\n",
    "    }\n",
    "\n",
    "need_feed_value_nodes = [node_x, node_y, node_k, node_b]\n",
    "\n",
    "sorted_node = topologic(convert_feed_dict_to_graph(feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "3c89bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in sorted_node:\n",
    "    node.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "cba1f56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " I am loss\n",
      "\n",
      " I am sigmoid\n",
      "\n",
      " I am linear\n",
      "\n",
      " I am x\n",
      "\n",
      " I am k\n",
      "\n",
      " I am y\n",
      "\n",
      " I am b\n"
     ]
    }
   ],
   "source": [
    "for node in sorted_node[::-1]:\n",
    "    print('\\n I am {}'.format(node.name))\n",
    "    node.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b3d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "96d2f968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'value is too small, I need update myself to 0.3861182465707451\n",
      "k'value is too small, I need update myself to 0.4286512588727166\n"
     ]
    }
   ],
   "source": [
    "# x,y也更新？？？\n",
    "learning_rate = 1e-1\n",
    "for node in sorted_node:\n",
    "    if node.is_trainable:\n",
    "        node.value = node.value + -1 * node.gradients[node] * learning_rate\n",
    "        cmp = 'large' if node.gradients[node] > 0 else 'small'\n",
    "        print(\"{}'value is too {}, I need update myself to {}\".format(node.name, cmp,node.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16149305",
   "metadata": {},
   "source": [
    "### 最后的封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "b3ce7983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(graph_sorted_nodes):\n",
    "    for node in graph_sorted_nodes:\n",
    "        node.forward()\n",
    "        #加一段代码\n",
    "        if isinstance(node,Loss):\n",
    "            print('Loss value: {}'.format(node.value))\n",
    "        \n",
    "def backward(graph_sorted_nodes):\n",
    "    for node in graph_sorted_nodes[::-1]:\n",
    "#         print('\\n I am {}'.format(node.name))\n",
    "        node.backward()\n",
    "\n",
    "def optimize(graph_nodes, learning_rate = 1e-1):\n",
    "    for node in graph_nodes:\n",
    "        if node.is_trainable:\n",
    "            node.value = node.value + -1 * node.gradients[node] * learning_rate\n",
    "            cmp = 'large' if node.gradients[node] > 0 else 'small'\n",
    "            print(\"{}'value is too {}, I need update myself to {}\".format(node.name, cmp,node.value))\n",
    "            \n",
    "def run_one_epoch(graph_sorted_nodes):\n",
    "    forward(graph_sorted_nodes)\n",
    "    backward(graph_sorted_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff12d82a",
   "metadata": {},
   "source": [
    "## 完整的依次求值 求导 求值的流程是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "c7895dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value: 1.3578421759877876e-05\n",
      "b'value is too small, I need update myself to 0.38741156105437113\n",
      "k'value is too small, I need update myself to 0.4325312023235947\n"
     ]
    }
   ],
   "source": [
    "run_one_epoch(sorted_node)\n",
    "optimize(sorted_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "d2429de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value: 3.2576152278405414e-09\n",
      "b'value is too small, I need update myself to 0.39008936050376825\n",
      "k'value is too small, I need update myself to 0.4405646006717858\n",
      "Loss value: 3.0426083937612127e-09\n",
      "b'value is too small, I need update myself to 0.39009078963136484\n",
      "k'value is too small, I need update myself to 0.4405688880545756\n",
      "Loss value: 2.841796308085599e-09\n",
      "b'value is too small, I need update myself to 0.3900921707791161\n",
      "k'value is too small, I need update myself to 0.4405730314978295\n",
      "Loss value: 2.6542414425047897e-09\n",
      "b'value is too small, I need update myself to 0.39009350555919736\n",
      "k'value is too small, I need update myself to 0.44057703583807317\n",
      "Loss value: 2.479068228271334e-09\n",
      "b'value is too small, I need update myself to 0.39009479552952336\n",
      "k'value is too small, I need update myself to 0.4405809057490511\n",
      "Loss value: 2.3154589576549534e-09\n",
      "b'value is too small, I need update myself to 0.3900960421955807\n",
      "k'value is too small, I need update myself to 0.44058464574722306\n",
      "Loss value: 2.162649956941535e-09\n",
      "b'value is too small, I need update myself to 0.39009724701219756\n",
      "k'value is too small, I need update myself to 0.4405882601970737\n",
      "Loss value: 2.019928012796202e-09\n",
      "b'value is too small, I need update myself to 0.39009841138525364\n",
      "k'value is too small, I need update myself to 0.4405917533162419\n",
      "Loss value: 1.8866270353899555e-09\n",
      "b'value is too small, I need update myself to 0.39009953667333164\n",
      "k'value is too small, I need update myself to 0.44059512918047583\n",
      "Loss value: 1.7621249423436639e-09\n",
      "b'value is too small, I need update myself to 0.390100624189313\n",
      "k'value is too small, I need update myself to 0.44059839172842\n",
      "Loss value: 1.6458407490205346e-09\n",
      "b'value is too small, I need update myself to 0.3901016752019197\n",
      "k'value is too small, I need update myself to 0.44060154476623997\n",
      "Loss value: 1.5372318514277667e-09\n",
      "b'value is too small, I need update myself to 0.390102690937203\n",
      "k'value is too small, I need update myself to 0.4406045919720899\n",
      "Loss value: 1.4357914888963923e-09\n",
      "b'value is too small, I need update myself to 0.39010367257998274\n",
      "k'value is too small, I need update myself to 0.4406075369004291\n",
      "Loss value: 1.3410463747376331e-09\n",
      "b'value is too small, I need update myself to 0.39010462127523704\n",
      "k'value is too small, I need update myself to 0.440610382986192\n",
      "Loss value: 1.2525544836098765e-09\n",
      "b'value is too small, I need update myself to 0.3901055381294454\n",
      "k'value is too small, I need update myself to 0.44061313354881704\n",
      "Loss value: 1.1699029854027468e-09\n",
      "b'value is too small, I need update myself to 0.390106424211886\n",
      "k'value is too small, I need update myself to 0.44061579179613897\n",
      "Loss value: 1.0927063156387847e-09\n",
      "b'value is too small, I need update myself to 0.39010728055588956\n",
      "k'value is too small, I need update myself to 0.44061836082814954\n",
      "Loss value: 1.020604373669587e-09\n",
      "b'value is too small, I need update myself to 0.3901081081600499\n",
      "k'value is too small, I need update myself to 0.4406208436406307\n",
      "Loss value: 9.532608399830255e-10\n",
      "b'value is too small, I need update myself to 0.3901089079893948\n",
      "k'value is too small, I need update myself to 0.44062324312866524\n",
      "Loss value: 8.903616047969925e-10\n",
      "b'value is too small, I need update myself to 0.3901096809765158\n",
      "k'value is too small, I need update myself to 0.4406255620900283\n",
      "Loss value: 8.31613300567468e-10\n",
      "b'value is too small, I need update myself to 0.39011042802266116\n",
      "k'value is too small, I need update myself to 0.44062780322846434\n",
      "Loss value: 7.767419315929199e-10\n",
      "b'value is too small, I need update myself to 0.39011114999879093\n",
      "k'value is too small, I need update myself to 0.4406299691568536\n",
      "Loss value: 7.254915941660022e-10\n",
      "b'value is too small, I need update myself to 0.39011184774659674\n",
      "k'value is too small, I need update myself to 0.44063206240027103\n",
      "Loss value: 6.776232813862501e-10\n",
      "b'value is too small, I need update myself to 0.3901125220794872\n",
      "k'value is too small, I need update myself to 0.4406340853989424\n",
      "Loss value: 6.329137669355171e-10\n",
      "b'value is too small, I need update myself to 0.39011317378353977\n",
      "k'value is too small, I need update myself to 0.4406360405111\n",
      "Loss value: 5.911545627327117e-10\n",
      "b'value is too small, I need update myself to 0.3901138036184206\n",
      "k'value is too small, I need update myself to 0.4406379300157425\n",
      "Loss value: 5.521509453622714e-10\n",
      "b'value is too small, I need update myself to 0.39011441231827343\n",
      "k'value is too small, I need update myself to 0.4406397561153011\n",
      "Loss value: 5.157210469927768e-10\n",
      "b'value is too small, I need update myself to 0.3901150005925784\n",
      "k'value is too small, I need update myself to 0.4406415209382161\n",
      "Loss value: 4.816950062252308e-10\n",
      "b'value is too small, I need update myself to 0.39011556912698175\n",
      "k'value is too small, I need update myself to 0.4406432265414262\n",
      "Loss value: 4.499141752280207e-10\n",
      "b'value is too small, I need update myself to 0.3901161185840976\n",
      "k'value is too small, I need update myself to 0.4406448749127738\n",
      "Loss value: 4.2023037911009334e-10\n",
      "b'value is too small, I need update myself to 0.3901166496042829\n",
      "k'value is too small, I need update myself to 0.4406464679733297\n",
      "Loss value: 3.9250522433652836e-10\n",
      "b'value is too small, I need update myself to 0.3901171628063858\n",
      "k'value is too small, I need update myself to 0.4406480075796384\n",
      "Loss value: 3.6660945278967217e-10\n",
      "b'value is too small, I need update myself to 0.3901176587884692\n",
      "k'value is too small, I need update myself to 0.44064949552588867\n",
      "Loss value: 3.4242233854527667e-10\n",
      "b'value is too small, I need update myself to 0.39011813812850976\n",
      "k'value is too small, I need update myself to 0.44065093354601037\n",
      "Loss value: 3.198311244658458e-10\n",
      "b'value is too small, I need update myself to 0.3901186013850732\n",
      "k'value is too small, I need update myself to 0.44065232331570076\n",
      "Loss value: 2.9873049603320555e-10\n",
      "b'value is too small, I need update myself to 0.3901190490979671\n",
      "k'value is too small, I need update myself to 0.4406536664543824\n",
      "Loss value: 2.7902208994567097e-10\n",
      "b'value is too small, I need update myself to 0.39011948178887135\n",
      "k'value is too small, I need update myself to 0.44065496452709524\n",
      "Loss value: 2.606140351557119e-10\n",
      "b'value is too small, I need update myself to 0.39011989996194785\n",
      "k'value is too small, I need update myself to 0.4406562190463248\n",
      "Loss value: 2.434205242442318e-10\n",
      "b'value is too small, I need update myself to 0.39012030410442916\n",
      "k'value is too small, I need update myself to 0.4406574314737688\n",
      "Loss value: 2.2736141310772878e-10\n",
      "b'value is too small, I need update myself to 0.3901206946871877\n",
      "k'value is too small, I need update myself to 0.44065860322204436\n",
      "Loss value: 2.123618470547806e-10\n",
      "b'value is too small, I need update myself to 0.39012107216528547\n",
      "k'value is too small, I need update myself to 0.4406597356563377\n",
      "Loss value: 1.9835191163365622e-10\n",
      "b'value is too small, I need update myself to 0.3901214369785056\n",
      "k'value is too small, I need update myself to 0.44066083009599816\n",
      "Loss value: 1.852663064951677e-10\n",
      "b'value is too small, I need update myself to 0.3901217895518657\n",
      "k'value is too small, I need update myself to 0.44066188781607846\n",
      "Loss value: 1.7304404081155621e-10\n",
      "b'value is too small, I need update myself to 0.3901221302961141\n",
      "k'value is too small, I need update myself to 0.4406629100488235\n",
      "Loss value: 1.6162814878485454e-10\n",
      "b'value is too small, I need update myself to 0.3901224596082092\n",
      "k'value is too small, I need update myself to 0.4406638979851088\n",
      "Loss value: 1.5096542398092588e-10\n",
      "b'value is too small, I need update myself to 0.390122777871783\n",
      "k'value is too small, I need update myself to 0.44066485277583023\n",
      "Loss value: 1.4100617115879666e-10\n",
      "b'value is too small, I need update myself to 0.39012308545758884\n",
      "k'value is too small, I need update myself to 0.44066577553324765\n",
      "Loss value: 1.3170397451689992e-10\n",
      "b'value is too small, I need update myself to 0.3901233827239338\n",
      "k'value is too small, I need update myself to 0.44066666733228266\n",
      "Loss value: 1.2301548124265405e-10\n",
      "b'value is too small, I need update myself to 0.3901236700170973\n",
      "k'value is too small, I need update myself to 0.44066752921177305\n",
      "Loss value: 1.149001993350233e-10\n",
      "b'value is too small, I need update myself to 0.39012394767173464\n",
      "k'value is too small, I need update myself to 0.4406683621756851\n",
      "Loss value: 1.073203087895604e-10\n",
      "b'value is too small, I need update myself to 0.3901242160112679\n",
      "k'value is too small, I need update myself to 0.44066916719428484\n",
      "Loss value: 1.0024048523783492e-10\n",
      "b'value is too small, I need update myself to 0.39012447534826294\n",
      "k'value is too small, I need update myself to 0.44066994520527\n",
      "Loss value: 9.362773524279061e-11\n",
      "b'value is too small, I need update myself to 0.39012472598479425\n",
      "k'value is too small, I need update myself to 0.4406706971148639\n",
      "Loss value: 8.745124247228996e-11\n",
      "b'value is too small, I need update myself to 0.39012496821279724\n",
      "k'value is too small, I need update myself to 0.4406714237988728\n",
      "Loss value: 8.168222399341502e-11\n",
      "b'value is too small, I need update myself to 0.3901252023144087\n",
      "k'value is too small, I need update myself to 0.44067212610370726\n",
      "Loss value: 7.629379609040346e-11\n",
      "b'value is too small, I need update myself to 0.3901254285622961\n",
      "k'value is too small, I need update myself to 0.4406728048473694\n",
      "Loss value: 7.12608489294744e-11\n",
      "b'value is too small, I need update myself to 0.3901256472199753\n",
      "k'value is too small, I need update myself to 0.44067346082040704\n",
      "Loss value: 6.655992949253665e-11\n",
      "b'value is too small, I need update myself to 0.39012585854211806\n",
      "k'value is too small, I need update myself to 0.44067409478683534\n",
      "Loss value: 6.216913222986652e-11\n",
      "b'value is too small, I need update myself to 0.390126062774849\n",
      "k'value is too small, I need update myself to 0.4406747074850282\n",
      "Loss value: 5.8067996952630294e-11\n",
      "b'value is too small, I need update myself to 0.39012626015603263\n",
      "k'value is too small, I need update myself to 0.440675299628579\n",
      "Loss value: 5.423741344283427e-11\n",
      "b'value is too small, I need update myself to 0.3901264509155505\n",
      "k'value is too small, I need update myself to 0.4406758719071326\n",
      "Loss value: 5.0659532383345175e-11\n",
      "b'value is too small, I need update myself to 0.3901266352755695\n",
      "k'value is too small, I need update myself to 0.44067642498718973\n",
      "Loss value: 4.7317682137603573e-11\n",
      "b'value is too small, I need update myself to 0.39012681345080086\n",
      "k'value is too small, I need update myself to 0.44067695951288377\n",
      "Loss value: 4.419629104432455e-11\n",
      "b'value is too small, I need update myself to 0.39012698564875026\n",
      "k'value is too small, I need update myself to 0.4406774761067319\n",
      "Loss value: 4.128081483317485e-11\n",
      "b'value is too small, I need update myself to 0.39012715206995985\n",
      "k'value is too small, I need update myself to 0.44067797537036074\n",
      "Loss value: 3.855766883340263e-11\n",
      "b'value is too small, I need update myself to 0.3901273129082422\n",
      "k'value is too small, I need update myself to 0.44067845788520776\n",
      "Loss value: 3.6014164653677695e-11\n",
      "b'value is too small, I need update myself to 0.39012746835090595\n",
      "k'value is too small, I need update myself to 0.440678924213199\n",
      "Loss value: 3.36384510335376e-11\n",
      "b'value is too small, I need update myself to 0.3901276185789743\n",
      "k'value is too small, I need update myself to 0.44067937489740405\n",
      "Loss value: 3.1419458621039356e-11\n",
      "b'value is too small, I need update myself to 0.39012776376739605\n",
      "k'value is too small, I need update myself to 0.4406798104626692\n",
      "Loss value: 2.934684836678517e-11\n",
      "b'value is too small, I need update myself to 0.39012790408524933\n",
      "k'value is too small, I need update myself to 0.440680231416229\n",
      "Loss value: 2.7410963344192682e-11\n",
      "b'value is too small, I need update myself to 0.39012803969593884\n",
      "k'value is too small, I need update myself to 0.44068063824829745\n",
      "Loss value: 2.5602783740454084e-11\n",
      "b'value is too small, I need update myself to 0.3901281707573862\n",
      "k'value is too small, I need update myself to 0.4406810314326395\n",
      "Loss value: 2.3913884820819016e-11\n",
      "b'value is too small, I need update myself to 0.39012829742221405\n",
      "k'value is too small, I need update myself to 0.440681411427123\n",
      "Loss value: 2.2336397662722574e-11\n",
      "b'value is too small, I need update myself to 0.3901284198379239\n",
      "k'value is too small, I need update myself to 0.4406817786742525\n",
      "Loss value: 2.0862972479145297e-11\n",
      "b'value is too small, I need update myself to 0.39012853814706794\n",
      "k'value is too small, I need update myself to 0.44068213360168457\n",
      "Loss value: 1.9486744381663564e-11\n",
      "b'value is too small, I need update myself to 0.39012865248741524\n",
      "k'value is too small, I need update myself to 0.4406824766227265\n",
      "Loss value: 1.820130136621721e-11\n",
      "b'value is too small, I need update myself to 0.3901287629921123\n",
      "k'value is too small, I need update myself to 0.44068280813681776\n",
      "Loss value: 1.7000654452526117e-11\n",
      "b'value is too small, I need update myself to 0.3901288697898382\n",
      "k'value is too small, I need update myself to 0.4406831285299954\n",
      "Loss value: 1.5879209763027644e-11\n",
      "b'value is too small, I need update myself to 0.3901289730049544\n",
      "k'value is too small, I need update myself to 0.44068343817534406\n",
      "Loss value: 1.4831742455170035e-11\n",
      "b'value is too small, I need update myself to 0.39012907275764985\n",
      "k'value is too small, I need update myself to 0.4406837374334303\n",
      "Loss value: 1.3853372382238317e-11\n",
      "b'value is too small, I need update myself to 0.3901291691640808\n",
      "k'value is too small, I need update myself to 0.44068402665272316\n",
      "Loss value: 1.2939541340833011e-11\n",
      "b'value is too small, I need update myself to 0.39012926233650635\n",
      "k'value is too small, I need update myself to 0.4406843061699998\n",
      "Loss value: 1.2085991838119569e-11\n",
      "b'value is too small, I need update myself to 0.3901293523834191\n",
      "k'value is too small, I need update myself to 0.44068457631073815\n",
      "Loss value: 1.1288747248592784e-11\n",
      "b'value is too small, I need update myself to 0.39012943940967165\n",
      "k'value is too small, I need update myself to 0.44068483738949576\n",
      "Loss value: 1.0544093286930237e-11\n",
      "b'value is too small, I need update myself to 0.39012952351659863\n",
      "k'value is too small, I need update myself to 0.4406850897102767\n",
      "Loss value: 9.848560699034895e-12\n",
      "b'value is too small, I need update myself to 0.3901296048021348\n",
      "k'value is too small, I need update myself to 0.44068533356688533\n",
      "Loss value: 9.198909096048324e-12\n",
      "b'value is too small, I need update myself to 0.39012968336092935\n",
      "k'value is too small, I need update myself to 0.44068556924326885\n",
      "Loss value: 8.592111853563697e-12\n",
      "b'value is too small, I need update myself to 0.3901297592844557\n",
      "k'value is too small, I need update myself to 0.44068579701384786\n",
      "Loss value: 8.025342014519616e-12\n",
      "b'value is too small, I need update myself to 0.3901298326611185\n",
      "k'value is too small, I need update myself to 0.44068601714383626\n",
      "Loss value: 7.495959109178569e-12\n",
      "b'value is too small, I need update myself to 0.3901299035763564\n",
      "k'value is too small, I need update myself to 0.44068622988955003\n",
      "Loss value: 7.0014968593341635e-12\n",
      "b'value is too small, I need update myself to 0.3901299721127417\n",
      "k'value is too small, I need update myself to 0.44068643549870584\n",
      "Loss value: 6.539651681832902e-12\n",
      "b'value is too small, I need update myself to 0.3901300383500763\n",
      "k'value is too small, I need update myself to 0.4406866342107097\n",
      "Loss value: 6.108271956703853e-12\n",
      "b'value is too small, I need update myself to 0.39013010236548495\n",
      "k'value is too small, I need update myself to 0.4406868262569356\n",
      "Loss value: 5.705348001740526e-12\n",
      "b'value is too small, I need update myself to 0.3901301642335049\n",
      "k'value is too small, I need update myself to 0.44068701186099535\n",
      "Loss value: 5.329002710898552e-12\n",
      "b'value is too small, I need update myself to 0.39013022402617265\n",
      "k'value is too small, I need update myself to 0.4406871912389987\n",
      "Loss value: 4.9774828044942955e-12\n",
      "b'value is too small, I need update myself to 0.39013028181310816\n",
      "k'value is too small, I need update myself to 0.44068736459980523\n",
      "Loss value: 4.649150662415006e-12\n",
      "b'value is too small, I need update myself to 0.39013033766159566\n",
      "k'value is too small, I need update myself to 0.4406875321452677\n",
      "Loss value: 4.342476694535841e-12\n",
      "b'value is too small, I need update myself to 0.3901303916366621\n",
      "k'value is too small, I need update myself to 0.44068769407046693\n",
      "Loss value: 4.056032212741815e-12\n",
      "b'value is too small, I need update myself to 0.39013044380115286\n",
      "k'value is too small, I need update myself to 0.4406878505639393\n",
      "Loss value: 3.788482776098831e-12\n",
      "b'value is too small, I need update myself to 0.3901304942158051\n",
      "k'value is too small, I need update myself to 0.440688001807896\n"
     ]
    }
   ],
   "source": [
    "# 查看梯度下降过程\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "for i in range(100):\n",
    "    run_one_epoch(sorted_node)\n",
    "    __loss_node = sorted_node[-1]\n",
    "    assert isinstance(__loss_node,Loss)\n",
    "    \n",
    "    loss_history.append(__loss_node.value)\n",
    "    optimize(sorted_node,learning_rate = 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "54cda526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "97d86651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.tick_params(axis='x',colors='white')\n",
    "plt.tick_params(axis='y',colors='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "dd263aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "f67b0bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8471207043197627"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(sorted_node[2].value * sorted_node[3].value + sorted_node[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "30255a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84712258543166"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_node[1].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "ed4621d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Placeholder:b,\n",
       " Placeholder:y,\n",
       " Placeholder:k,\n",
       " Placeholder:x,\n",
       " Linear:linear,\n",
       " Sigmoid:sigmoid,\n",
       " Sigmoid:loss]"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2630033b",
   "metadata": {},
   "source": [
    "# 到这里已经完成了核心内容，可以向前运算，向后运算，梯度更新"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9246e347",
   "metadata": {},
   "source": [
    "# 如何处理多维数据？？\n",
    "2.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d06319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3da973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb28d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d5d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2062866f",
   "metadata": {},
   "source": [
    "# 请止步!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f427cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, inputs= [],name = None):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "        self.name = name\n",
    "        \n",
    "        for node in inputs:\n",
    "            node.outputs.append(self)\n",
    "            \n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name} ,i calculate myself value\")\n",
    "    def __repr__(self):\n",
    "        return f'Node:{self.name}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4d08f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x k b y 是需要输入实际值的数 定义为placeholder\n",
    "\n",
    "class Placeholder(Node):\n",
    "    def __init__(self,name = None):\n",
    "        Node.__init__(self,name = name)\n",
    "\n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name},my value is {self.value},i calculate myself value, I have been given value\")\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Placeholder:{self.name}'\n",
    "    \n",
    "node_x = Placeholder(name = 'x')\n",
    "node_k = Placeholder(name = 'k')\n",
    "node_b = Placeholder(name = 'b')\n",
    "node_y = Placeholder(name = 'y')\n",
    "node_linear = Node(inputs = [node_x, node_k, node_b],name = 'linear')\n",
    "node_sigmoid = Node(inputs = [node_linear],name = 'sigmoid')\n",
    "node_loss = Node(inputs = [node_y,node_sigmoid],name = 'loss')\n",
    "\n",
    "def convert_feed_dict_to_graph(feed_dict):\n",
    "    \n",
    "    need_expand = [n for n in feed_dict]\n",
    "    \n",
    "    computing_graph = defaultdict(list)\n",
    "\n",
    "    while need_expand:\n",
    "        n = need_expand.pop(0)\n",
    "\n",
    "        if n in computing_graph:continue\n",
    "            \n",
    "        if isinstance(n,Placeholder): n.value = feed_dict[n]\n",
    "\n",
    "        for m in n.outputs:\n",
    "            computing_graph[n].append(m)\n",
    "            need_expand.append(m)\n",
    "    return computing_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "11641efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am y ,i calculate myself value, I have been given value\n",
      "I am x ,i calculate myself value, I have been given value\n",
      "I am k ,i calculate myself value, I have been given value\n",
      "I am b ,i calculate myself value, I have been given value\n",
      "I am linear ,i calculate myself value by myself\n",
      "I am sigmoid ,i calculate myself value by myself\n",
      "I am loss ,i calculate myself value by myself\n"
     ]
    }
   ],
   "source": [
    "for node in sorted_node:\n",
    "    node.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "991e6a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Node:\n",
    "    def __init__(self, inputs= [],name = None):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "        self.name = name\n",
    "        self.value = None\n",
    "        self.gradients = dict()  #存储loss对某个偏导的值\n",
    "        \n",
    "        for node in inputs:\n",
    "            node.outputs.append(self)\n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name},i calculate myself value by myself\")\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Node:{self.name}'\n",
    "    \n",
    "class Linear(Node):\n",
    "    def __init__(self,x,k,b,name = None):\n",
    "        Node.__init__(self,inputs = [x,k,b],name = name)\n",
    "\n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name} ,my value is {self.value},i calculate myself value by my self!\")\n",
    "        x, k, b = self.inputs[0], self.inputs[1], self.inputs[2]\n",
    "        self.value = k.value * x.value + b.value\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Linear:{self.name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "bddf9f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Node):\n",
    "    def __init__(self,x,name = None):\n",
    "        Node.__init__(self,inputs = [x],name = name)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name} ,my value is {self.value},i calculate myself value by my self!\")\n",
    "        x = self.inputs[0]\n",
    "        self.value = self._sigmoid(x.value)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Sigmoid:{self.name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "602026c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(Node):\n",
    "    \"\"\"MSE\"\"\"\n",
    "    def __init__(self,y,yhat,name = None):\n",
    "        Node.__init__(self,inputs = [y,yhat],name = name)\n",
    "    \n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name} ,my value is {self.value},i calculate myself value by my self!\")\n",
    "        y,yhat = self.inputs[0], self.inputs[1]\n",
    "        self.value = np.mean((y.value - yhat.value)**2)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Sigmoid:{self.name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4cf7182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_x = Placeholder(name = 'x')\n",
    "node_k = Placeholder(name = 'k')\n",
    "node_b = Placeholder(name = 'b')\n",
    "node_y = Placeholder(name = 'y')\n",
    "node_linear = Linear(node_x, node_k, node_b,name = 'linear')\n",
    "node_sigmoid = Sigmoid(x = node_linear,name = 'sigmoid')\n",
    "node_loss = Loss(y = node_y, yhat = node_sigmoid,name = 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "01c340bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "22bd891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am k,my value is 0.06687895212397421,i calculate myself value, I have been given value\n",
      "I am b,my value is 0.38,i calculate myself value, I have been given value\n",
      "I am y,my value is 0.2993957062307556,i calculate myself value, I have been given value\n",
      "I am x,my value is 3,i calculate myself value, I have been given value\n",
      "I am linear ,my value is 2.650973615995455,i calculate myself value by my self!\n",
      "I am sigmoid ,my value is 0.9340709734538888,i calculate myself value by my self!\n",
      "I am loss ,my value is 0.01786359719043438,i calculate myself value by my self!\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {\n",
    "    node_x :3,\n",
    "    node_y :random.random(),\n",
    "    node_k :random.random(),\n",
    "    node_b :0.38\n",
    "    }\n",
    "\n",
    "need_feed_value_nodes = [node_x, node_y, node_k, node_b]\n",
    "\n",
    "sorted_node = topologic(convert_feed_dict_to_graph(feed_dict))\n",
    "for node in sorted_node:\n",
    "    node.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b228bde6",
   "metadata": {},
   "source": [
    "# 以上就是向前传播的内容\n",
    "$\\partial$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6af64b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, inputs= [],name = None):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "        self.name = name\n",
    "        self.value = None\n",
    "        \n",
    "        for node in inputs:\n",
    "            node.outputs.append(self)\n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name},i calculate myself value by myself\")\n",
    "        \n",
    "    def backward(self):\n",
    "        for n in self.inputs:\n",
    "            print('get ∂{}/∂{}'.format(self.name,n.name))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Node:{self.name}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ae1bc044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am loss\n",
      "get ∂loss/∂y\n",
      "get ∂loss/∂sigmoid\n",
      "I am sigmoid\n",
      "get ∂sigmoid/∂linear\n",
      "I am y\n",
      "I am linear\n",
      "get ∂linear/∂x\n",
      "get ∂linear/∂k\n",
      "get ∂linear/∂b\n",
      "I am k\n",
      "I am b\n",
      "I am x\n"
     ]
    }
   ],
   "source": [
    "# for node in sorted_node:\n",
    "#     node.forward()\n",
    "\n",
    "for node in sorted_node[::-1]:\n",
    "    print(f'I am {node.name}')\n",
    "    node.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a44053a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, inputs= [],name = None):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "        self.name = name\n",
    "        self.value = None\n",
    "        self.gradients = dict()  #存储loss对某个偏导的值\n",
    "        \n",
    "        for node in inputs:\n",
    "            node.outputs.append(self)\n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name},i calculate myself value by myself\")\n",
    "        \n",
    "    def backward(self):\n",
    "        for n in self.inputs:\n",
    "            print('get ∂{}/∂{}'.format(self.name,n.name))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Node:{self.name}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ef3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1db0a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, inputs= [],name = None):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "        self.name = name\n",
    "        self.value = None\n",
    "        self.gradients = dict()  #存储loss对某个偏导的值\n",
    "        \n",
    "        for node in inputs:\n",
    "            node.outputs.append(self)\n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name},i calculate myself value by myself\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Node:{self.name}'\n",
    "\n",
    "class Placeholder(Node):\n",
    "    def __init__(self,name = None):\n",
    "        Node.__init__(self,name = name)\n",
    "\n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name},my value is {self.value},i calculate myself value, I have been given value\")\n",
    "    \n",
    "    def backward(self):\n",
    "        print('I got myself gradients: {}'.format(self.outputs[0].gradients[self]))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Placeholder:{self.name}'\n",
    "\n",
    "    \n",
    "class Linear(Node):\n",
    "    def __init__(self,x,k,b,name = None):\n",
    "        Node.__init__(self,inputs = [x,k,b],name = name)\n",
    "\n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name} ,my value is {self.value},i calculate myself value by my self!\")\n",
    "        x, k, b = self.inputs[0], self.inputs[1], self.inputs[2]\n",
    "        self.value = k.value * x.value + b.value\n",
    "    \n",
    "    def backward(self):\n",
    "        self.gradients[self.inputs[0]] ='*'.join([self.outputs[0].gradients[self],\n",
    "                                                 '∂{} / ∂{}'.format(self.name, self.inputs[0].name)])\n",
    "        self.gradients[self.inputs[1]] ='*'.join([self.outputs[0].gradients[self],\n",
    "                                                 '∂{} / ∂{}'.format(self.name, self.inputs[1].name)])\n",
    "        self.gradients[self.inputs[2]] ='*'.join([self.outputs[0].gradients[self],\n",
    "                                                 '∂{} / ∂{}'.format(self.name, self.inputs[2].name)])\n",
    "\n",
    "        print('self.gradients[self.inputs[0]] {}'.format(self.gradients[self.inputs[0]]))\n",
    "        print('self.gradients[self.inputs[1]] {}'.format(self.gradients[self.inputs[1]]))\n",
    "        print('self.gradients[self.inputs[2]] {}'.format(self.gradients[self.inputs[2]]))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Linear:{self.name}'\n",
    "\n",
    "\n",
    "    \n",
    "class Sigmoid(Node):\n",
    "    def __init__(self,x,name = None):\n",
    "        Node.__init__(self,inputs = [x],name = name)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name} ,my value is {self.value},i calculate myself value by my self!\")\n",
    "        x = self.inputs[0]\n",
    "        self.value = self._sigmoid(x.value)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.gradients[self.inputs[0]] ='*'.join([self.outputs[0].gradients[self]\n",
    "                                                  , 'get ∂{}/∂{}'.format(self.name, self.inputs[0].name)])\n",
    "\n",
    "        print('self.gradients[self.inputs[0]] {}'.format(self.inputs[0]))\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Sigmoid:{self.name}'\n",
    "    \n",
    "    \n",
    "class Loss(Node):\n",
    "    \"\"\"MSE\"\"\"\n",
    "    def __init__(self,y,yhat,name = None):\n",
    "        Node.__init__(self,inputs = [y,yhat],name = name)\n",
    "    \n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name} ,my value is {self.value},i calculate myself value by my self!\")\n",
    "        y,yhat = self.inputs[0], self.inputs[1]\n",
    "        self.value = np.mean((y.value - yhat.value)**2)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.gradients[self.inputs[0]] = 'get ∂{}/∂{}'.format(self.name, self.inputs[0].name)\n",
    "        self.gradients[self.inputs[1]] = 'get ∂{}/∂{}'.format(self.name, self.inputs[1].name)\n",
    "\n",
    "        print('self.gradients[self.inputs[0]] {}'.format(self.inputs[0]))\n",
    "        print('self.gradients[self.inputs[1]] {}'.format(self.inputs[1]))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Sigmoid:{self.name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "a49afb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am loss\n",
      "self.gradients[self.inputs[0]] Placeholder:y\n",
      "self.gradients[self.inputs[1]] Sigmoid:sigmoid\n",
      "I am sigmoid\n",
      "self.gradients[self.inputs[0]] Linear:linear\n",
      "I am linear\n",
      "self.gradients[self.inputs[0]] get ∂loss/∂sigmoid*get ∂sigmoid/∂linear*∂linear / ∂x\n",
      "self.gradients[self.inputs[1]] get ∂loss/∂sigmoid*get ∂sigmoid/∂linear*∂linear / ∂k\n",
      "self.gradients[self.inputs[2]] get ∂loss/∂sigmoid*get ∂sigmoid/∂linear*∂linear / ∂b\n",
      "I am b\n",
      "I got myself gradients: get ∂loss/∂sigmoid*get ∂sigmoid/∂linear*∂linear / ∂b\n",
      "I am k\n",
      "I got myself gradients: get ∂loss/∂sigmoid*get ∂sigmoid/∂linear*∂linear / ∂k\n",
      "I am x\n",
      "I got myself gradients: get ∂loss/∂sigmoid*get ∂sigmoid/∂linear*∂linear / ∂x\n",
      "I am y\n",
      "I got myself gradients: get ∂loss/∂y\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for node in sorted_node[::-1]:\n",
    "    print(f'I am {node.name}')\n",
    "    node.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "fb98128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Node):\n",
    "    def __init__(self,x,k,b,name = None):\n",
    "        Node.__init__(self,inputs = [x,k,b],name = name)\n",
    "\n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name} ,my value is {self.value},i calculate myself value by my self!\")\n",
    "        x, k, b = self.inputs[0], self.inputs[1], self.inputs[2]\n",
    "        self.value = k.value * x.value + b.value\n",
    "    \n",
    "    def backward(self):\n",
    "        x, k, b = self.inputs[0], self.inputs[1], self.inputs[2]\n",
    "        self.gradients[self.inputs[0]] = self.outputs[0].gradients[self] * k.value\n",
    "        self.gradients[self.inputs[1]] = self.outputs[0].gradients[self] * x.value\n",
    "        self.gradients[self.inputs[2]] = self.outputs[0].gradients[self] * 1\n",
    "\n",
    "        print('self.gradients[self.inputs[0]] {}'.format(self.gradients[self.inputs[0]]))\n",
    "        print('self.gradients[self.inputs[1]] {}'.format(self.gradients[self.inputs[1]]))\n",
    "        print('self.gradients[self.inputs[2]] {}'.format(self.gradients[self.inputs[2]]))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Linear:{self.name}'\n",
    "\n",
    "class Sigmoid(Node):\n",
    "    def __init__(self,x,name = None):\n",
    "        Node.__init__(self,inputs = [x],name = name)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name} ,my value is {self.value},i calculate myself value by my self!\")\n",
    "        x = self.inputs[0]\n",
    "        self.value = self._sigmoid(x.value)\n",
    "    \n",
    "    def backward(self):\n",
    "        x = self.inputs[0]\n",
    "        self.gradients[self.inputs[0]] =self.outputs[0].gradients[self] * (self._sigmoid(x.value) * (1 - self._sigmoid(x.value)))\n",
    "        print('self.gradients[self.inputs[0]] {}'.format(self.gradients[self.inputs[0]]))\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Sigmoid:{self.name}'\n",
    "\n",
    "\n",
    "    \n",
    "class Loss(Node):\n",
    "    \"\"\"MSE\"\"\"\n",
    "    def __init__(self,y,yhat,name = None):\n",
    "        Node.__init__(self,inputs = [y,yhat],name = name)\n",
    "    \n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name} ,my value is {self.value},i calculate myself value by my self!\")\n",
    "        y,yhat = self.inputs[0], self.inputs[1]\n",
    "        self.value = np.mean((y.value - yhat.value)**2)\n",
    "    \n",
    "    def backward(self):\n",
    "        y,yhat = self.inputs[0], self.inputs[1]\n",
    "        self.gradients[self.inputs[0]] = 2 * np.mean(y.value - yhat.value)\n",
    "        self.gradients[self.inputs[1]] = -2 * np.mean(y.value - yhat.value)\n",
    "\n",
    "        print('self.gradients[self.inputs[0]] {}'.format(self.gradients[self.inputs[0]]))\n",
    "        print('self.gradients[self.inputs[1]] {}'.format(self.gradients[self.inputs[1]]))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Sigmoid:{self.name}'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "8fb07f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " I am loss\n",
      "self.gradients[self.inputs[0]] 0.14228049374906804\n",
      "self.gradients[self.inputs[1]] -0.14228049374906804\n",
      "\n",
      " I am sigmoid\n",
      "self.gradients[self.inputs[0]] -0.014867014773847519\n",
      "\n",
      " I am linear\n",
      "self.gradients[self.inputs[0]] -0.008059390560958682\n",
      "self.gradients[self.inputs[1]] -0.044601044321542556\n",
      "self.gradients[self.inputs[2]] -0.014867014773847519\n",
      "\n",
      " I am k\n",
      "I got myself gradients: -0.044601044321542556\n",
      "\n",
      " I am x\n",
      "I got myself gradients: -0.008059390560958682\n",
      "\n",
      " I am y\n",
      "I got myself gradients: 0.14228049374906804\n",
      "\n",
      " I am b\n",
      "I got myself gradients: -0.014867014773847519\n"
     ]
    }
   ],
   "source": [
    "for node in sorted_node[::-1]:\n",
    "    print('\\n I am {}'.format(node.name))\n",
    "    node.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16310301",
   "metadata": {},
   "source": [
    "## 以上是反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a2b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, inputs= [],name = None, is_trainable = False):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "        self.name = name\n",
    "        self.value = None\n",
    "        self.gradients = dict()  #存储loss对某个偏导的值\n",
    "        self.is_trainable = is_trainable\n",
    "        \n",
    "        for node in inputs:\n",
    "            node.outputs.append(self)\n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name},i calculate myself value by myself\")\n",
    "        \n",
    "node_x = Placeholder(name = 'x')\n",
    "node_k = Placeholder(name = 'k',is_trainable = True)\n",
    "node_b = Placeholder(name = 'b',is_trainable = True)\n",
    "node_y = Placeholder(name = 'y')\n",
    "node_linear = Linear(node_x, node_k, node_b,name = 'linear')\n",
    "node_sigmoid = Sigmoid(x = node_linear,name = 'sigmoid')\n",
    "node_loss = Loss(y = node_y, yhat = node_sigmoid,name = 'loss')\n",
    "\n",
    "class Placeholder(Node):\n",
    "    def __init__(self,name = None):\n",
    "        Node.__init__(self,name = name, is_trainable= is_trainable)\n",
    "\n",
    "    def forward(self):\n",
    "        print(f\"I am {self.name},my value is {self.value},i calculate myself value, I have been given value\")\n",
    "    \n",
    "    def backward(self):\n",
    "        print('I got myself gradients: {}'.format(self.outputs[0].gradients[self]))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Placeholder:{self.name}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4635f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4cddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd57a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bdac94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc19612f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf2787d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5756572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc916c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
